{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Dataset_y_data_augmentation.ipynb","provenance":[{"file_id":"1x2iV92KUCL2rr70p3Jwb9LMeMdnsmj7e","timestamp":1627517977794}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"gnz3-c4GTXm9"},"source":["# Vamos a utilizar un dataset de perros y gatos para explorar técnicas de Data Augmentation"]},{"cell_type":"code","metadata":{"id":"AvXs-cneTXm-","executionInfo":{"status":"ok","timestamp":1627930055768,"user_tz":180,"elapsed":234,"user":{"displayName":"Santiago Rivier","photoUrl":"","userId":"02114253809716218523"}}},"source":["import numpy as np\n","import pandas as pd\n","%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import os"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"PHVTt9_UTXnC","executionInfo":{"status":"ok","timestamp":1627930061211,"user_tz":180,"elapsed":5059,"user":{"displayName":"Santiago Rivier","photoUrl":"","userId":"02114253809716218523"}}},"source":["import tensorflow as tf\n","from tensorflow import keras"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zk78JBqATXnG"},"source":["### DATASET:"]},{"cell_type":"markdown","metadata":{"id":"PQ0QRvPATXnH"},"source":["El Dataset contiene 4000 imágenes de gatos y perros (2000 gatos y 2000 perros). Vamos a usar 2000 imágenes para entrenar, 1000 para validación, 1000 para test."]},{"cell_type":"code","metadata":{"id":"E-DnI3CtwyaC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627930065388,"user_tz":180,"elapsed":4184,"user":{"displayName":"Santiago Rivier","photoUrl":"","userId":"02114253809716218523"}},"outputId":"213caea5-6c4b-414d-ed59-56a9f0775dc6"},"source":["#subir el archivo perros_y_gatos.zip\n","# está acá: https://drive.google.com/file/d/1WgbH_Xt421hNhD4gcfwsvtVsFheJKefm/view?usp=sharing\\\n","!gdown --id 1WgbH_Xt421hNhD4gcfwsvtVsFheJKefm"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1WgbH_Xt421hNhD4gcfwsvtVsFheJKefm\n","To: /content/perros_y_gatos.zip\n","90.8MB [00:00, 135MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VBhyd6J6wcjs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a4d3ff1-af1c-4c60-e882-29e5ad4979fb"},"source":["!unzip /content/perros_y_gatos.zip > /dev/null"],"execution_count":null,"outputs":[{"output_type":"stream","text":["replace test/cats/cat.1501.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","replace test/cats/cat.1502.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","replace test/cats/cat.1503.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","replace test/cats/cat.1504.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","replace test/cats/cat.1505.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n","error:  invalid response [a]\n","replace test/cats/cat.1505.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u9zISTEdxYyZ"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BIYh_FdY0l8U"},"source":["cd /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tomzRUadTXnJ"},"source":["train_dir = './train'\n","validation_dir = './validation'\n","test_dir = './test'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KDrroygKTXnM"},"source":["### Preprocesamiento de los datos"]},{"cell_type":"markdown","metadata":{"id":"assnLl85TXnN"},"source":["* Leer las imágenes\n","* Decodificar los JPEG en imágenes de píxeles RGB\n","* Convertir estas imágenes en tensores de valores en punto flotante\n","* Reescalar los valores de los píxeles al intervalo [0,1]\n"]},{"cell_type":"code","metadata":{"id":"HuOLXZOJTXnN"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_0bUApO-TXnR"},"source":["Link : https://keras.io/preprocessing/image/"]},{"cell_type":"code","metadata":{"id":"-yyUlq53TXnS"},"source":["# Así generamos batches desde los directorios de imágenes\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=(150, 150),\n","        batch_size=20,\n","        class_mode='binary')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(150, 150),\n","        batch_size=20,\n","        class_mode='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3wT7I-yTXnX"},"source":["# i = 1\n","# for batch in train_datagen.flow(train_generator, batch_size=1,\n","#                           save_to_dir='.', save_prefix='img', save_format='jpeg'):\n","#     i += 1\n","#     if i > 6:\n","#         break\n","\n","# import matplotlib.image as mpimg\n","# import glob\n","# import os\n","\n","# files =glob.glob(\"./*.jpeg\")\n","# plt.figure(figsize=(10,5))\n","# i = 1\n","# for f in files:\n","#     if i > 6:\n","#         break \n","#     plt.subplot(2,3,i)\n","#     image = mpimg.imread(f)\n","#     plt.imshow(image)\n","#     i+=1\n","#     os.remove(f)\n","    \n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jM2FYJIEyEEA"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"27lf0gY6TXnb"},"source":["from tensorflow.keras import layers\n","from tensorflow.keras import models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dfXCWT9TXne"},"source":["model = models.Sequential()\n","\n","#### COMPLETAR #####\n","# agregar las siguientes capas:\n","# convolucional f=(3,3), # de filtros: 32, activación relu\n","# max pooling f=2, s=2\n","# convolucional f=(3,3), # de filtros: 64, activación relu\n","# max pooling f=2, s=2\n","# convolucional f=(3,3), # de filtros: 128, activación relu\n","# max pooling f=2, s=2\n","# convolucional f=(3,3), # de filtros: 128, activación relu\n","# max pooling f=2, s=2\n","# capa flatten\n","# capa densa de 512 elementos activación relu\n","# capa densa con un output de 1 elemento con activación sigmoidea\n","model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(64, (3,3), activation='relu'))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(128, (3,3), activation='relu'))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(128, (3,3), activation='relu'))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dense(1, activation='relu'))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0cp9q94YTXng"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"__ppSmEsTXnj"},"source":["from tensorflow.keras import optimizers\n","\n","# compilar el modelo con binary_crossentropy y optimizador RMSprop con\n","# learning rate 1e-4, la métrica a usar es la accuracy (acc)\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=optimizers.RMSprop(lr=1e-4),\n","              metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCXq57TfTXnn"},"source":["# utilizar model.fit_generator para entrenar\n","history = model.fit_generator(\n","      train_generator,\n","      steps_per_epoch=100,\n","      epochs=5,\n","      validation_data=validation_generator,\n","      validation_steps=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cl1_o5PlTXnq"},"source":["pd.DataFrame(history.history).plot(figsize=(8, 5))\n","plt.grid(True)\n","plt.gca().set_ylim(0, 1)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBcVvX-HTXns"},"source":["from tensorflow.keras import backend as K \n","\n","K.clear_session()\n","del model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0lNZqKvXTXnv"},"source":["### DATA AUGMENTATION"]},{"cell_type":"markdown","metadata":{"id":"O4YwS2n2TXnw"},"source":["Distorsión, Rotación, Crop, Flip horizontal: \n","![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"idlLIwPuTXnw"},"source":["Vamos a distorsionar (estirando y escalando), rotar las imágenes, invertirlas horizontalmente, hacer zoom en una región, esto va a ser aleatorio dentro de un cierto rango, utilizar ImageDataGenerator con parámetros para que esto ocurra.\n","\n","https://keras.io/api/preprocessing/image/\n","\n","https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/image/image_data_generator.py\n","\n","https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/image/affine_transformations.py\n","\n","usar:\n","\n","- rotation_range -> rango aleatorio de angulo de rotacions\n","- width_shift_range -> rango aleatorio de desplazamiento en x expresado como proporcion de la imagen [0,1]\n","- height_shift_range -> rango aleatorio de desplazamiento en y expresado como proporcion de la imagen [0,1]\n","- shear_range -> rango aleatorio de 'shear' o cillamiento https://en.wikipedia.org/wiki/Shear_mapping [0,1]\n","- zoom_range -> rango aleatorio de zoom de la imagen [0,1]\n","- horizontal_flip -> boolean (si se flipea aleatoriamente la imagen en la dirección horizontal)"]},{"cell_type":"code","metadata":{"id":"_4AfTtUYTXnx"},"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,rotation_range=50,\n","    )\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=(150, 150),\n","        batch_size=32,\n","        class_mode='binary')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","        validation_dir,\n","        target_size=(150, 150),\n","        batch_size=32,\n","        class_mode='binary')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tyBxlQH-TXnz"},"source":["### Veamos algunas imágenes"]},{"cell_type":"code","metadata":{"id":"Gy6UlyMqTXnz"},"source":["i = 1\n","for batch in train_datagen.flow(train_generator, batch_size=1,\n","                          save_to_dir='.', save_prefix='img', save_format='jpeg'):\n","    i += 1\n","    if i > 6:\n","        break\n","\n","import matplotlib.image as mpimg\n","import glob\n","import os\n","\n","files =glob.glob(\".\\*.jpeg\")\n","plt.figure(figsize=(10,5))\n","i = 1\n","for f in files:\n","    if i > 6:\n","        break \n","    plt.subplot(2,3,i)\n","    image = mpimg.imread(f)\n","    plt.imshow(image)\n","    i+=1\n","    os.remove(f)\n","    \n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7EIKRxpHTXn2"},"source":["model = models.Sequential()\n","\n","#### COMPLETAR #####\n","### usar el mismo modelo de antes\n","\n","# agregar las siguientes capas:\n","# convolucional f=(3,3), # de filtros: 32, activación relu\n","# max pooling f=2, s=2\n","# convolucional f=(3,3), # de filtros: 64, activación relu\n","# max pooling f=2, s=2\n","# convolucional f=(3,3), # de filtros: 128, activación relu\n","# max pooling f=2, s=2\n","# convolucional f=(3,3), # de filtros: 128, activación relu\n","# max pooling f=2, s=2\n","# capa flatten\n","# capa densa de 512 elementos activación relu\n","# capa densa con un output de 1 elemento con activación sigmoidea\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=optimizers.RMSprop(lr=1e-4),\n","              metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zw0xmIUuTXn4"},"source":["history = model.fit_generator(\n","      train_generator,\n","      steps_per_epoch=100,\n","      epochs=5,\n","      validation_data=validation_generator,\n","      validation_steps=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jn93iMM7TXn8"},"source":["pd.DataFrame(history.history).plot(figsize=(8, 5))\n","plt.grid(True)\n","plt.gca().set_ylim(0, 1)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fD_0v5BTXn_"},"source":["keras.backend.clear_session\n","del model"],"execution_count":null,"outputs":[]}]}
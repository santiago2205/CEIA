{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Resnet50_en_keras.ipynb","provenance":[{"file_id":"14aKayg8puBmOaKiLHFetrL28_CnOzsAJ","timestamp":1628204271557},{"file_id":"1vQ74apOmtteayNAwCpbCbBQp7FqpWkwx","timestamp":1626323353875}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZSHM9RYaE98k"},"source":["## ResNets\n","\n","* Vimos que entrenar redes muy profundas presenta dificultades:\n"," * Una son los gradientes que tienden a cero o explotan (vanishing y exploding gradients).\n"," * La otra es la degradación de la performance en el training set.\n","* Una de las técnicas para resolverlo son las redes residuales.\n","* Vamos a construir los bloques para armar una ResNet.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"W1l912Q2E98k"},"source":["\n","En las ResNets las 'skip connections' o 'shortcuts' o 'residual connections' permiten 'saltar capas'\n","a \"shortcut\" or a \"skip connection\" allows the model to skip layers:  \n","\n","<img src=\"https://raw.githubusercontent.com/enggen/Deep-Learning-Coursera/master/Convolutional%20Neural%20Networks/Week2/ResNets/images/skip_connection_kiank.png\" style=\"width:650px;height:200px;\">\n","<caption><center> <u> <font color='purple'> **Figure 2** </u><font color='purple'>  : Un bloque ResNet donde se exhibe una **skip-connection** <br> </center></caption>\n","\n","La imagen a la izquierda muestra el camino principal de la red. La imagen de la derecha agrega un 'shortcut' al camino principal. Apilando estos bloques podemos armar redes con arquitecturas muy profundas.\n","\n","Agregar un bloque adicional con una conexión residual hace muy fácil imitar la función identidad, por lo tanto agregar bloques residuales agrega poco riesgo de degradar la performance en el set de entrenamiento.\n","    \n","Hay dos bloques principales, el que se usa depende de si la dimensión de salida del bloque es la misma que la de entrada o no:\n","    * El bloque con tamaño de entrada = tamaño de salida se llama bloque identidad (identity block).\n","    * El bloque con entrada != tamaño se llama bloque convolucional (convolutional block).\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"SLkRVvNrE98k"},"source":["### Bloque identidad\n","\n","El bloque identidad es un bloque estándar utilizado en ResNets, y corresponde al caso en que la activación de entrada (por ej. $a^{[l]}$)  tiene la misma dimensión a la activación de salida ($a^{[l+2]}$). Para esquematizar los diferentes pasos de lo que ocurre en un bloque de identidad de una ResNet, el siguiente diagrama muestra los pasos indivuales:\n","\n","<img src=\"https://github.com/enggen/Deep-Learning-Coursera/raw/master/Convolutional%20Neural%20Networks/Week2/ResNets/images/idblock2_kiank.png\" style=\"width:650px;height:150px;\">\n","<caption><center> <u> <font color='purple'> **Figura 1** </u><font color='purple'>  : **Bloque Identidad.** Skip connection \"salta\" 2 capas. </center></caption>\n","\n","El camino superior es el 'atajo' o 'shortcut'. El camino superior es el 'camino principal'. En este diagrama se han hecho explícitos el paso convolucional y la no-linearidad ReLU. Para acelerar el entrenamiento también agregamos un paso de Batch Normalization. \n","    \n","En el ejercicio de abajo hay que implementar una versión un poco más poderosa del bloque identidad, en el cual 'saltamos' conexiones sobre 3 capas ocultas en vez de 2. Se ve así:\n","\n","<img src=\"https://github.com/enggen/Deep-Learning-Coursera/raw/master/Convolutional%20Neural%20Networks/Week2/ResNets/images/idblock3_kiank.png\" style=\"width:650px;height:150px;\">\n","<caption><center> <u> <font color='purple'> **Figura 2** </u><font color='purple'>  : **Bloque Identidad.** Skip connection \"salta\" 3 capas.</center></caption>"]},{"cell_type":"code","metadata":{"id":"hKN287R2E98k","executionInfo":{"status":"ok","timestamp":1628257430424,"user_tz":180,"elapsed":230,"user":{"displayName":"Santiago Rivier","photoUrl":"","userId":"02114253809716218523"}}},"source":["# imports\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from tensorflow.keras import backend\n","import numpy as np\n","import pydot\n","import tensorflow as tf"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"3L3hgQE5E98l","executionInfo":{"status":"ok","timestamp":1628255849178,"user_tz":180,"elapsed":239,"user":{"displayName":"Santiago Rivier","photoUrl":"","userId":"02114253809716218523"}}},"source":["def identity_block(input_tensor, kernel_size, filters, stage, block):\n","    \"\"\"\n","    El bloque identidad tiene el tamaño del input igual al tamaño del output\n","    \n","    # Argumentos\n","        input_tensor: tensor de entrada\n","        kernel_size: el default es 3, tamaño del kernel de la capa media en el camino principal\n","        filters: lista de enteros, cantidad de filtros de las 3 capas CONV en el camino principal\n","        stage: entrada, rótulo de la etapa actual, usado para generar los nombres de las capas\n","        block: 'a', 'b'..., rótulo del bloque actual, usado para generar nombres de capas\n","        \n","    # Retorna\n","        Tensor de salida del bloque.\n","    \"\"\"\n","    X_shortcut = input_tensor\n","    filters1, filters2, filters3 = filters\n","    if backend.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    conv_name_base = 'res' + str(stage) + block + '_branch' # nombre base para las capas convolucionales\n","    bn_name_base = 'bn' + str(stage) + block + '_branch' # nombre base para las capas residuales\n","\n","    # sub-bloque a\n","    # para los nombres utilizar conv_name_base + '2a' para capas conv y bn_name_base + '2a' \n","    # agregar una capa Conv2D, usar he_normal como kernel_initializer, kernel_size -> (1,1), # de filtros filters1\n","    # agregar Batch Normalization\n","    # agregar activación ReLU\n","    # esta parte YA fue implementada\n","    \n","    x = layers.Conv2D(filters1, (1, 1),\n","                      kernel_initializer='he_normal',\n","                      name=conv_name_base + '2a')(input_tensor)\n","    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n","    x = layers.Activation('relu')(x)\n","    \n","    # sub-bloque b\n","    # para los nombres utilizar conv_name_base + '2b' para capas conv y bn_name_base + '2b' \n","    # agregar una capa Conv2D, usar he_normal como kernel_initializer, kernel_size -> el parametro kernel_size\n","    # # de filtros filters2, padding=\"same\"\n","    # agregar Batch Normalization\n","    # agregar activación ReLU\n","\n","    x = layers.Conv2D(filters = filters2, kernel_size = (kernel_size, kernel_size), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer='he_normal')(x)\n","    x = layers.BatchNormalization(axis = bn_axis, name = bn_name_base + '2b')(x)\n","    x = layers.Activation('relu')(x)\n","    \n","    # sub-bloque c\n","    # para los nombres utilizar conv_name_base + '2c' para capas conv y bn_name_base + '2c' \n","    # agregar una capa Conv2D, usar he_normal como kernel_initializer, kernel_size -> (1,1), # de filtros filters3\n","    # agregar Batch Normalization\n","    # agregar activación ReLU\n","\n","    x = layers.Conv2D(filters = filters3, kernel_size = (1, 1), strides = (1,1), name = conv_name_base + '2c', kernel_initializer='he_normal')(x)\n","    x = layers.BatchNormalization(axis = bn_axis, name = bn_name_base + '2c')(x)\n","    x = layers.Activation('relu')(x)\n","    \n","    # sumar el tensor de entrada al resultado de las anteriores operaciones (usar la función layers.add(...))\n","    # agregar activación ReLU\n","\n","    x = layers.Add()([x, X_shortcut])\n","    x = layers.Activation('relu')(x)\n","    \n","    # retornar el tensor resultante\n","    return x"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"jaVctCiyE98l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628255852868,"user_tz":180,"elapsed":238,"user":{"displayName":"Santiago Rivier","photoUrl":"","userId":"02114253809716218523"}},"outputId":"cf964c74-363e-4e24-bbab-fd364dd4c26b"},"source":["A_prev = layers.Input([4, 4, 6])\n","X = np.random.randn(3, 4, 4, 6)\n","A = identity_block(A_prev, 2, [2, 4, 6],1 ,'a')\n","model = models.Model(A_prev, A, name='identity_block')\n","model.summary()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"identity_block\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 4, 4, 6)]    0                                            \n","__________________________________________________________________________________________________\n","res1a_branch2a (Conv2D)         (None, 4, 4, 2)      14          input_2[0][0]                    \n","__________________________________________________________________________________________________\n","bn1a_branch2a (BatchNormalizati (None, 4, 4, 2)      8           res1a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 4, 4, 2)      0           bn1a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res1a_branch2b (Conv2D)         (None, 4, 4, 4)      36          activation_3[0][0]               \n","__________________________________________________________________________________________________\n","bn1a_branch2b (BatchNormalizati (None, 4, 4, 4)      16          res1a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 4, 4, 4)      0           bn1a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res1a_branch2c (Conv2D)         (None, 4, 4, 6)      30          activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn1a_branch2c (BatchNormalizati (None, 4, 4, 6)      24          res1a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 4, 4, 6)      0           bn1a_branch2c[0][0]              \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 4, 4, 6)      0           activation_5[0][0]               \n","                                                                 input_2[0][0]                    \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 4, 4, 6)      0           add[0][0]                        \n","==================================================================================================\n","Total params: 128\n","Trainable params: 104\n","Non-trainable params: 24\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j1e0xW7mE98m"},"source":["Salida esperada:\n","\n","Model: \"identity_block\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_27 (InputLayer)           [(None, 4, 4, 6)]    0                                            \n","__________________________________________________________________________________________________\n","res1a_branch2a (Conv2D)         (None, 4, 4, 2)      14          input_27[0][0]                   \n","__________________________________________________________________________________________________\n","bn1a_branch2a (BatchNormalizati (None, 4, 4, 2)      8           res1a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 4, 4, 2)      0           bn1a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res1a_branch2b (Conv2D)         (None, 4, 4, 4)      36          activation_64[0][0]              \n","__________________________________________________________________________________________________\n","bn1a_branch2b (BatchNormalizati (None, 4, 4, 4)      16          res1a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 4, 4, 4)      0           bn1a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res1a_branch2c (Conv2D)         (None, 4, 4, 6)      30          activation_65[0][0]              \n","__________________________________________________________________________________________________\n","bn1a_branch2c (BatchNormalizati (None, 4, 4, 6)      24          res1a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, 4, 4, 6)      0           bn1a_branch2c[0][0]              \n","                                                                 input_27[0][0]                   \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 4, 4, 6)      0           add_21[0][0]                     \n","==================================================================================================\n","Total params: 128\n","Trainable params: 104\n","Non-trainable params: 24\n","__________________________________________________________________________________________________"]},{"cell_type":"markdown","metadata":{"id":"sXKDCXTaE98m"},"source":["## Bloque convolucional\n","\n","El bloque convolucional de la ResNet es el segundo tipo de bloque. Se puede usar este tipo de bloque cuando las dimensiones de la entrada y de la salida no coinciden.\n","\n","\n","<img src=\"https://github.com/enggen/Deep-Learning-Coursera/raw/master/Convolutional%20Neural%20Networks/Week2/ResNets/images/convblock_kiank.png\" style=\"width:650px;height:150px;\">\n","<caption><center> <u> <font color='purple'> **Figura 3** </u><font color='purple'>  : **Bloque convolucional** </center></caption>\n","\n","* La capa CONV2D en el 'shortcut' es usada para redimensionar la entrada $x$ a una dimensión diferente, de tal manera que las dimensiones coinciden en la suma final necesaria para sumar el la skip connection al 'flujo' principal.\n","* Por ejemplo, para reducir la altura y ancho de las activaciones por un factor de 2, podemos usar una convolución 1x1 con un stride de 2.\n","* La capa CONV2D en el la skip connection no usa ninguna función no-lineal. Su rol principal es simplemente aplicar una función lineal que reduce la dimensión de la entrada para que coincidan las dimensiones.\n"]},{"cell_type":"code","metadata":{"id":"DSmSSvBRE98n","executionInfo":{"status":"ok","timestamp":1628256877816,"user_tz":180,"elapsed":247,"user":{"displayName":"Santiago Rivier","photoUrl":"","userId":"02114253809716218523"}}},"source":["def conv_block(input_tensor,\n","               kernel_size,\n","               filters,\n","               stage,\n","               block,\n","               strides=(2, 2)):\n","    \"\"\"Un bloque que tiene una capa convolucional como shortcut.\n","\n","    # Argumentos\n","        input_tensor: tensor de entrada\n","        kernel_size: el default es 3, tamaño del kernel de la capa media en el camino principal\n","        filters: lista de enteros, cantidad de filtros de las 3 capas CONV en el camino principal\n","        stage: entrada, rótulo de la etapa actual, usado para generar los nombres de las capas\n","        block: 'a', 'b'..., rótulo del bloque actual, usado para generar nombres de capas\n","        strides: Strides para la primera capa convolucional del bloque.\n","\n","    # Retorna\n","        Tensor de salida del bloque.\n","    \"\"\"\n","    X_shortcut = input_tensor\n","    filters1, filters2, filters3 = filters\n","    if backend.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    \n","    # sub-bloque a\n","    # para los nombres utilizar conv_name_base + '2a' para capas conv y bn_name_base + '2a' \n","    # agregar una capa Conv2D, usar he_normal como kernel_initializer, kernel_size -> (1,1)\n","    # agregar Batch Normalization\n","    # agregar activación ReLU\n","    \n","    x = layers.Conv2D(filters1, (1, 1), strides=strides,\n","                      kernel_initializer='he_normal',\n","                      name=conv_name_base + '2a')(input_tensor)\n","    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n","    x = layers.Activation('relu')(x)\n","    \n","    # sub-bloque b\n","    # para los nombres utilizar conv_name_base + '2b' para capas conv y bn_name_base + '2b' \n","    # agregar una capa Conv2D, usar he_normal como kernel_initializer, kernel_size -> el parametro kernel_size\n","    # # de filtros filters2, padding=\"same\"\n","    # agregar Batch Normalization\n","    # agregar activación ReLU\n","    \n","    x = layers.Conv2D(filters = filters2, kernel_size = (kernel_size, kernel_size), padding = 'same', kernel_initializer='he_normal', name=conv_name_base + '2b')(x)\n","    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n","    x = layers.Activation('relu')(x)\n","\n","    # sub-bloque c\n","    # para los nombres utilizar conv_name_base + '2c' para capas conv y bn_name_base + '2c' \n","    # agregar una capa Conv2D, usar he_normal como kernel_initializer, kernel_size -> (1,1), # de filtros filters3\n","    # agregar Batch Normalization\n","    # agregar activación ReLU\n","    \n","    x = layers.Conv2D(filters = filters3, kernel_size = (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(x)\n","    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n","    x = layers.Activation('relu')(x)\n","\n","    # conexión shortcut:\n","    # agregar una capa convolucional que actúe sobre el tensor de entrada\n","    # esta capa de shortcut tiene filtros de tamaño 1x1 y stride (2,2)\n","    # agregar Batch Normalization\n","\n","    X_shortcut = layers.Conv2D(filters = filters3, kernel_size = (1, 1), strides = (2,2), padding = 'valid', name = conv_name_base + '1', kernel_initializer='he_normal')(X_shortcut)\n","    X_shortcut = layers.BatchNormalization(axis = bn_axis, name = bn_name_base + '1')(X_shortcut)\n","    \n","    # aplicar la conexión shortcut al tensor de entrada \n","    # y sumarle a esto el resultado de aplicar las anteriores operaciones (el camino principal) \n","    # a la entrada\n","    # agregar activación ReLU\n","\n","    x = layers.Add()([x, X_shortcut])\n","    x = layers.Activation('relu')(x)\n","\n","    # retornar el tensor resultante\n","    return x"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lSJFNKfE98n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628256880893,"user_tz":180,"elapsed":243,"user":{"displayName":"Santiago Rivier","photoUrl":"","userId":"02114253809716218523"}},"outputId":"10f92c75-5a14-4944-dafc-b66a1d122039"},"source":["A_prev = layers.Input([4, 4, 6])\n","X = np.random.randn(3, 4, 4, 6)\n","A = conv_block(A_prev, 2, [2, 4, 6],1 ,'a')\n","model = models.Model(A_prev, A, name='conv_block')\n","model.summary()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Model: \"conv_block\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 4, 4, 6)]    0                                            \n","__________________________________________________________________________________________________\n","res1a_branch2a (Conv2D)         (None, 2, 2, 2)      14          input_4[0][0]                    \n","__________________________________________________________________________________________________\n","bn1a_branch2a (BatchNormalizati (None, 2, 2, 2)      8           res1a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 2, 2, 2)      0           bn1a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res1a_branch2b (Conv2D)         (None, 2, 2, 4)      36          activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn1a_branch2b (BatchNormalizati (None, 2, 2, 4)      16          res1a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 2, 2, 4)      0           bn1a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res1a_branch2c (Conv2D)         (None, 2, 2, 6)      30          activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn1a_branch2c (BatchNormalizati (None, 2, 2, 6)      24          res1a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","res1a_branch1 (Conv2D)          (None, 2, 2, 6)      42          input_4[0][0]                    \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 2, 2, 6)      0           bn1a_branch2c[0][0]              \n","__________________________________________________________________________________________________\n","bn1a_branch1 (BatchNormalizatio (None, 2, 2, 6)      24          res1a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 2, 2, 6)      0           activation_12[0][0]              \n","                                                                 bn1a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 2, 2, 6)      0           add_1[0][0]                      \n","==================================================================================================\n","Total params: 194\n","Trainable params: 158\n","Non-trainable params: 36\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ex9x6YaHE98n"},"source":["Salida esperada:\n","\n","Model: \"conv_block\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_28 (InputLayer)           [(None, 4, 4, 6)]    0                                            \n","__________________________________________________________________________________________________\n","res1a_branch2a (Conv2D)         (None, 2, 2, 2)      14          input_28[0][0]                   \n","__________________________________________________________________________________________________\n","bn1a_branch2a (BatchNormalizati (None, 2, 2, 2)      8           res1a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 2, 2, 2)      0           bn1a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res1a_branch2b (Conv2D)         (None, 2, 2, 4)      36          activation_67[0][0]              \n","__________________________________________________________________________________________________\n","bn1a_branch2b (BatchNormalizati (None, 2, 2, 4)      16          res1a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 2, 2, 4)      0           bn1a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res1a_branch2c (Conv2D)         (None, 2, 2, 6)      30          activation_68[0][0]              \n","__________________________________________________________________________________________________\n","res1a_branch1 (Conv2D)          (None, 2, 2, 6)      42          input_28[0][0]                   \n","__________________________________________________________________________________________________\n","bn1a_branch2c (BatchNormalizati (None, 2, 2, 6)      24          res1a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn1a_branch1 (BatchNormalizatio (None, 2, 2, 6)      24          res1a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, 2, 2, 6)      0           bn1a_branch2c[0][0]              \n","                                                                 bn1a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 2, 2, 6)      0           add_22[0][0]                     \n","==================================================================================================\n","Total params: 194\n","Trainable params: 158\n","Non-trainable params: 36\n","__________________________________________________________________________________________________"]},{"cell_type":"markdown","metadata":{"id":"9NLJcLNZE98n"},"source":["## Función para armar ResNet50\n","\n","Con estos bloques es posible armar ResNet50. La siguiente imagen demuestra la arquitectura en detalle. \"ID BLOCK\" significa \"Identity Block\", \"ID BLOCK x3\" significa que debemos apilar 3 identity blocks juntos.\n","\n","<img src=\"https://github.com/enggen/Deep-Learning-Coursera/raw/master/Convolutional%20Neural%20Networks/Week2/ResNets/images/resnet_kiank.png\" style=\"width:850px;height:150px;\">\n","<caption><center> <u> <font color='purple'> **Figure 4** </u><font color='purple'>  : **ResNet-50** </center></caption>\n","\n"]},{"cell_type":"code","metadata":{"id":"hEWxqoXyE98n","executionInfo":{"status":"ok","timestamp":1628261552539,"user_tz":180,"elapsed":238,"user":{"displayName":"Santiago Rivier","photoUrl":"","userId":"02114253809716218523"}}},"source":["def ResNet50(input_shape=(224, 224, 3), classes=1000):\n","    \"\"\"\n","    Instancia la arquitectura ResNet50.\n","    \n","    # Argumentos\n","        input_tensor: tensor de Keras opcional para usar de imagen de entrada al modelo\n","        optional Keras tensor (i.e. output of `layers.Input()`)\n","            to use as image input for the model.\n","        input_shape: tiene que tener 3 canales de entrada\n","        classes: número opcional de clases en las que clasificar las imágenes\n","\n","    # Retorna\n","        Un modelo de Keras\n","    \"\"\"\n","\n","    img_input = layers.Input(input_shape)\n","    \n","    if backend.image_data_format() == 'channels_last':\n","        bn_axis = 3\n","    else:\n","        bn_axis = 1\n","\n","    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n","\n","    x = layers.Conv2D(64, (7, 7), strides=(2, 2), padding='valid', kernel_initializer='he_normal', name='conv1')(x)\n","    x = layers.BatchNormalization(axis=3, name='bn_conv1')(x)\n","    x = layers.Activation('relu')(x)\n","    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n","    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n","\n","    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n","\n","    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', strides=(2, 2))\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n","\n","    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', strides=(2, 2))\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n","\n","    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a', strides=(2, 2))\n","    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n","    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n","\n","    x = layers.GlobalAveragePooling2D((2,2), name='avg_pool')(x)\n","\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","    \n","    inputs = img_input\n","    # Create model.\n","    model = models.Model(inputs, x, name='resnet50')\n","\n","    return model"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"sEPc4pXLE98n","colab":{"base_uri":"https://localhost:8080/","height":358},"executionInfo":{"status":"error","timestamp":1628261558087,"user_tz":180,"elapsed":257,"user":{"displayName":"Santiago Rivier","photoUrl":"","userId":"02114253809716218523"}},"outputId":"5c999fb5-7ff3-40ad-951e-d1f02a6d9573"},"source":["# comparar la estructura con la ResNet en keras\n","model = ResNet50(input_shape=(224, 224, 3), classes=1000)\n","model.summary()"],"execution_count":64,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-db788495e48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# comparar la estructura con la ResNet en keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-63-0064271aad23>\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(input_shape, classes)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentity_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-c5b9cfb7e1fa>\u001b[0m in \u001b[0;36mconv_block\u001b[0;34m(input_tensor, kernel_size, filters, stage, block, strides)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# agregar activación ReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_shortcut\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 970\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1108\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    876\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2623\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2625\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2626\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_elemwise_op_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;31m# If the inputs have different ranks, we have to reshape them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# to make them broadcastable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36m_compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     79\u001b[0m           raise ValueError(\n\u001b[1;32m     80\u001b[0m               \u001b[0;34m'Operands could not be broadcast '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m               'together with shapes ' + str(shape1) + ' ' + str(shape2))\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0moutput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Operands could not be broadcast together with shapes (56, 56, 256) (28, 28, 256)"]}]}]}